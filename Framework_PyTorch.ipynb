{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lt1H5o-poBfF"
      },
      "source": [
        "# 1. \n",
        "## 필요한 framework, GPU 및 초기 parameter 세팅\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B1X8mpttn-Vi"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transfroms\n",
        "\n",
        "# 사용가능한 GPU 할당\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "torch.manual_seed(777)\n",
        "if device == 'cuda':\n",
        "    torch.cuda.manual_seed_all(777)\n",
        "print(device + \" is available\")\n",
        "\n",
        "learning_rate = 0.001 \n",
        "batch_size = 100  \n",
        "num_classes = 10  \n",
        "epochs = 5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dWzCD1LRn-vT"
      },
      "source": [
        "# 2.\n",
        "## torchvision에서 제공하는 MNIST 데이터 로드"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7YfkyOQioSBj"
      },
      "outputs": [],
      "source": [
        "train_set = torchvision.datasets.MNIST(\n",
        "    root = './data/MNIST',\n",
        "    train = True,             # train data\n",
        "    download = True,\n",
        "    transform = transfroms.Compose([\n",
        "        transfroms.ToTensor() \n",
        "    ])\n",
        ")\n",
        "test_set = torchvision.datasets.MNIST(\n",
        "    root = './data/MNIST',\n",
        "    train = False,            # test data\n",
        "    download = True,\n",
        "    transform = transfroms.Compose([\n",
        "        transfroms.ToTensor()\n",
        "    ])\n",
        ")\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size)\n",
        "test_loader = torch.utils.data.DataLoader(test_set, batch_size=batch_size)\n",
        "\n",
        "examples = enumerate(train_set)\n",
        "batch_idx, (example_data, example_targets) = next(examples)\n",
        "example_data.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VQ_MTPYyoUbo"
      },
      "source": [
        "# 3.\n",
        "## Model을 class로 만들기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LQee8cNioUjL"
      },
      "outputs": [],
      "source": [
        " class ConvNet(nn.Module):\n",
        "  def __init__(self): \n",
        "        super(ConvNet, self).__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5) # num of input_channels = 1, num of out_channels = 10, kernel size = 5, stribe = 1, padding = 0 인 convolution layer\n",
        "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5) # input_channels = 10, out_channels = 20, kernel size = 5, stribe = 1, padding = 0 인 convolution layer\n",
        "        self.drop2D = nn.Dropout2d(p=0.25, inplace=False) # 0.25의 확률로 각 노드를 0으로 turn-off\n",
        "        self.mp = nn.MaxPool2d(2) # kernel_size=2로 max값으로 pooling\n",
        "        self.fc1 = nn.Linear(320,100)  # input_size = 320, output_size = 100인 Fully-connected layer\n",
        "        self.fc2 = nn.Linear(100,10)  # input_size = 100, output_size = 10인 Fully-connected layer\n",
        "\n",
        "  def forward(self, x):\n",
        "        x = F.relu(self.mp(self.conv1(x))) # convolution layer(in:1, out:10) 연산 후 maxpooling 후 relu activation 함수 적용\n",
        "        x = F.relu(self.mp(self.conv2(x))) # convolution layer(in:10, out:20) 연산 후 maxpooling 후 relu activation 함수 적용\n",
        "        x = self.drop2D(x)  # 0.25 확률로 dropout\n",
        "        x = x.view(x.size(0), -1) # Flatten 시킴\n",
        "        x = self.fc1(x)  # Fully connected linear layer 1번 진행 320->100\n",
        "        x = self.fc2(x)  # Linear 한번 더 진행 100->10\n",
        "        return F.log_softmax(x)  # softmax함수의 log값 반환\n",
        " \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xDVGW05NoUri"
      },
      "source": [
        "# 4.\n",
        "## 모델, 평가기준(loss 함수), optim 함수 정의"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hn6FU1proUxO"
      },
      "outputs": [],
      "source": [
        "model = ConvNet().to(device)  # instance 생성\n",
        "criterion = nn.CrossEntropyLoss().to(device)    # loss 함수로 CrossEntropyLoss 사용\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)  # weight parameter 학습 시 Adam 알고리즘 사용;\n",
        " "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ccwsHldkoU3w"
      },
      "source": [
        "# 5.\n",
        "## training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XN9BQMZJoU8b"
      },
      "outputs": [],
      "source": [
        "for epoch in range(epochs): \n",
        "    avg_cost = 0\n",
        "\n",
        "    for data, target in train_loader:\n",
        "        data = data.to(device)  # data를 GPU(또는 cpu)에 얹음\n",
        "        target = target.to(device)  \n",
        "        optimizer.zero_grad() # 모든 model의 gradient 값을 0으로 설정 - 초기화 이유 : 새로운 가중치 편향에 대한 새로운 기울기를 구하기 위해\n",
        "        hypothesis = model(data) # predicte y값 계산\n",
        "        cost = criterion(hypothesis, target) # loss 계산\n",
        "        cost.backward() # loss의 gradient 계산\n",
        "        optimizer.step() # parameter update\n",
        "        avg_cost += cost / len(train_loader) \n",
        "    print('[Epoch: {:>4}] cost = {:>.9}'.format(epoch + 1, avg_cost))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "35KJ9PP9oVCI"
      },
      "source": [
        "# 6.\n",
        "## Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_aJMrF54oVGV"
      },
      "outputs": [],
      "source": [
        "model.eval()    # test mode로 설정\n",
        "with torch.no_grad():   # test시에는 gradient 추적하지 않음\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for data, target in test_loader:\n",
        "        data = data.to(device)\n",
        "        target = target.to(device)\n",
        "        out = model(data)  \n",
        "        preds = torch.max(out.data, 1)[1] \n",
        "        total += len(target) \n",
        "        correct += (preds==target).sum().item() # 맞은 개수 계산\n",
        "        \n",
        "    print('Test Accuracy: ', 100.*correct/total, '%')  # 정확도 계산 = 맞은 개수 / 전체 개수 * 100"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Framework_PyTorch.ipynb",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}